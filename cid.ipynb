{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Todos os import's necessários para o funcionamento do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy import sparse, stats\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Itens importantes para a Análise dos Dados, fazendo o carregamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv('C:/Users/Samsung/Downloads/train.csv/train.csv')\n",
    "df_teste = pd.read_csv('C:/Users/Samsung/Downloads/test.csv/test.csv')\n",
    "submissao = pd.read_csv('C:/Users/Samsung/Downloads/sample_submission.csv/sample_submission.csv')\n",
    "\n",
    "treino = df_treino.copy()\n",
    "teste = df_teste.copy()\n",
    "\n",
    "#Removendo target dos dados\n",
    "labels = treino.pop('target')\n",
    "y = labels.values\n",
    "\n",
    "#Remover e salvar o id de cada base da dado\n",
    "treino_id = treino.pop('id')\n",
    "teste_id = teste.pop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploração de Análise da Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisaoGeral(df):\n",
    "    '''funciona como o describe, mas é ampliado para melhor visualização dos dados'''\n",
    "\n",
    "    print(f\"Forma do Dataset: {df.shape}\")\n",
    "    sumario = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    sumario = sumario.reset_index()\n",
    "    sumario['Name'] = sumario['index']\n",
    "    sumario = sumario[['Name','dtypes']]\n",
    "    sumario['Missing'] = df.isnull().sum().values\n",
    "    sumario['Uniques'] = df.nunique().values\n",
    "\n",
    "    for nome in sumario['Name'].value_counts().index:\n",
    "        sumario.loc[sumario['Name'] == nome, 'Entropy'] = round(stats.entropy(df[nome].value_counts(normalize=True), base=2),2)\n",
    "    return sumario\n",
    "sumario = VisaoGeral(treino)\n",
    "display(sumario.head())\n",
    "\n",
    "#Descrever a informação obtida para melhor entendimento\n",
    "def Descrever_informacao(tno, tst):\n",
    "    \"\"\"Descrever a diferenca entre cada datasets\"\"\"\n",
    "\n",
    "    status = []\n",
    "    Analise = list(treino.columns)\n",
    "\n",
    "    for coluna in Analise:\n",
    "        dtreino = dict(treino[coluna].value_counts())\n",
    "        dteste = dict(teste[coluna].value_counts())\n",
    "\n",
    "        teste_nao_treino = set(dteste.keys()) - set(dtreino.keys())\n",
    "        treino_nao_teste = set(dtreino.keys()) - set(dteste.keys())\n",
    "\n",
    "        dict_treino_nao_teste = {key:value for key, value in dtreino.items() if key in treino_nao_teste}\n",
    "        dict_teste_nao_treino = {key:value for key, value in dteste.items() if key in teste_nao_treino}\n",
    "\n",
    "        items_teste, tot_teste = len(dteste), pd.Series(dteste).sum()\n",
    "        items_treino_nao_teste, tot_treino_nao_teste = len(dict_treino_nao_teste), pd.Series(dict_treino_nao_teste, dtype='float32').sum()\n",
    "        items_treino, tot_treino = len(dtreino), pd.Series(dtreino).sum()\n",
    "        items_teste_nao_treino, tot_teste_nao_treino = len(dict_teste_nao_treino), pd.Series(dict_teste_nao_treino, dtype='float32').sum()\n",
    "\n",
    "        status.append((\n",
    "            str(coluna),\n",
    "            str(items_treino_nao_teste) + ' (' + str(round(100* items_treino_nao_teste/ items_treino,1)) + '%)',\n",
    "            str(items_teste_nao_treino) + ' (' + str(round(100* items_teste_nao_treino/ items_teste,1)) + '%)'\n",
    "        ))\n",
    "\n",
    "    df_status = pd.DataFrame(status, columns=[\n",
    "        \"Variáveis\",\n",
    "        \"Valores únicos no treino e não no teste (%)\",\n",
    "        \"Valores únicos no teste e não no treino (%)\"])\n",
    "    return df_status\n",
    "Descrever_informacao(treino, teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Criação dos Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cores dos gráficos\n",
    "colores = [\"#e2e83f\", \"#753fe8\", \"#f1c40fff\", \"#8a327f\", \"#4d669e\",\"#2ecc4e\"]\n",
    "colores = sns.color_palette(colores)\n",
    "\n",
    "#Criando gráfico inicial dos objetivos\n",
    "total = len(df_treino)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.countplot(x='target', data = df_treino, palette = colores)\n",
    "g.set_title(\"Contagem das classes\", fontsize = 20)\n",
    "g.set_xlabel(\"Valores Target\", fontsize = 15)\n",
    "g.set_ylabel(\"Contagem\", fontsize = 15)\n",
    "sizes=[]\n",
    "# código para as porcentagens em cada barra\n",
    "for pc in g.patches:\n",
    "    height = pc.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(pc.get_x()+pc.get_width()/2.,\n",
    "            height + 6,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=14)\n",
    "g.set_ylim(0, max(sizes) * 1.25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Análise de Variáveis Binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos fazer um rede de dados, sabendo que tendo 5 variáveis binárias\n",
    "#Iremos plotar em 2 linhas e 3 colunas.\n",
    "\n",
    "rede = gridspec.GridSpec(2, 3)\n",
    "plt.figure(figsize=(16,20))\n",
    "\n",
    "#Teremos um contador de Plots em casa var. binária\n",
    "#Por essa razão utilizamos um loop\n",
    "coluna_bin = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n",
    "for b, coluna in enumerate(df_treino[coluna_bin]):\n",
    "    ax = plt.subplot(rede[b])\n",
    "    sns.countplot(x=coluna, data=df_treino, hue='target', palette=colores)\n",
    "    ax.set_ylabel('Count', fontsize=15)\n",
    "    ax.set_title(f'{coluna} Por classe', fontsize=18)\n",
    "    ax.set_xlabel(f'{coluna} Valores', fontsize=15)\n",
    "    sizes=[]\n",
    "    #Porcentagem em barra novamente\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        sizes.append(height)\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(height/total*100),\n",
    "                ha=\"center\", fontsize=12)\n",
    "    ax.set_ylim(0, max(sizes) * 1.15)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Análise de Variáveis Nominais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todas as colunas nominais = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n",
    "#Porém só trabalharemos com as que estão abaixo\n",
    "coluna_nom = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\n",
    "\n",
    "\n",
    "def Plotar_cat(df, cols, vis_row=5, vis_col=2):\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    grid = gridspec.GridSpec(vis_row,vis_col)\n",
    "    plt.figure(figsize=(17, 35)) #tamanho \n",
    "\n",
    "    #Loop para calcular o n de colunas e contar as plotagens\n",
    "    for n, col in enumerate(df_treino[cols]):\n",
    "        tmp = pd.crosstab(df_treino[col], df_treino['target'], normalize='index') * 100\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp.rename(columns={0:'No',1:'Yes'}, inplace=True)\n",
    "\n",
    "        ax = plt.subplot(grid[n]) #Preenchendo a rede\n",
    "        sns.countplot(x=col, data=df_treino, order=list(tmp[col].values), palette='Spectral')\n",
    "        ax.set_ylabel('Count', fontsize=15) #Eixo Y\n",
    "        ax.set_title(f'{col} Por Classe', fontsize=18) #Título\n",
    "        ax.set_xlabel(f'{col} values', fontsize=15) #Eixo X\n",
    "\n",
    "        # twinX - construir um segundo eixo para Y\n",
    "        gt = ax.twinx()\n",
    "        gt = sns.pointplot(x=col, y='Yes', data=tmp,\n",
    "                           order=list(tmp[col].values),\n",
    "                           color='black', legend=False)\n",
    "        gt.set_ylim(tmp['Yes'].min()-5,tmp['Yes'].max()*1.1)\n",
    "        gt.set_ylabel(\"Target %True(1)\", fontsize=14)\n",
    "        sizes=[] #Capturar os maiores valores de Y\n",
    "        for p in ax.patches: #Botar todos os objetos em loop\n",
    "            height = p.get_height()\n",
    "            sizes.append(height)\n",
    "            ax.text(p.get_x()+p.get_width()/2.,\n",
    "                    height + 3,\n",
    "                    '{:1.2f}%'.format(height/total*100),\n",
    "                    ha=\"center\", fontsize=14)\n",
    "        ax.set_ylim(0, max(sizes) * 1.15) #Montar os limites de y baseado nos maiores valores encontrados\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(hspace = 0.5, wspace=.4)\n",
    "    plt.show()\n",
    "\n",
    "Plotar_cat(df_treino, coluna_nom, vis_row=5, vis_col=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Análise da Variáveis Ordenadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#E corrigir dados da ord_1 e ord_2 para entender seus funcionamentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_ord = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4']\n",
    "Plotar_cat(df_treino, coluna_ord, vis_row=5, vis_col=2)\n",
    "\n",
    "# Vamos criar funções para conversão\n",
    "def ord_para_fac(df, name, categories):\n",
    "    ''' Conversao para uma ordem de fatores. '''\n",
    "    raw_cat = pd.Categorical(df[name], categories=categories, ordered=True)\n",
    "    labels, unique = pd.factorize(raw_cat, sort=True)\n",
    "    nova_ide = name + '_v2'\n",
    "    df[nova_ide] = labels\n",
    "\n",
    "def ord_para_num(name, df, categories):\n",
    "    ''' Conversao para ordem numérica ou alfabética. '''\n",
    "    raw_cat = pd.Categorical(df[name], categories=categories, ordered=True)\n",
    "    encoder = LabelEncoder()\n",
    "    encoded = encoder.fit_transform(raw_cat)\n",
    "    nova_ide = name + '_v2'\n",
    "    df[nova_ide] = encoded\n",
    "\n",
    "\n",
    "# Verificando as classes nas variáveis ordinais\n",
    "unique_ord0 = df_treino['ord_0'].unique()\n",
    "unique_ord1 = df_treino['ord_1'].unique()\n",
    "unique_ord2 = df_treino['ord_2'].unique()\n",
    "unique_ord3 = df_treino['ord_3'].unique()\n",
    "unique_ord4 = df_treino['ord_4'].unique()\n",
    "unique_ord5 = df_treino['ord_5'].unique()\n",
    "\n",
    "nome = 'ord_1'\n",
    "categorias = ['Recruta', 'Soldado', 'Expert', 'Grao-Mestre', 'Mestre']\n",
    "ord_para_fac(df_treino, nome, categorias)\n",
    "\n",
    "df_treino.columns\n",
    "\n",
    "\n",
    "nome = 'ord_2'\n",
    "categorias = ['Congelando', 'Frio', 'Calor', 'Quente', 'Fervendo', 'Muito quente']\n",
    "ord_para_fac(df_treino, nome, categorias)\n",
    "\n",
    "coluna_ord = ['ord_1_v2', 'ord_2_v2']\n",
    "Plotar_cat(df_treino, coluna_ord, vis_row=2, vis_col=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Caso excepcional da ord_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome = 'ord_5'\n",
    "categorias = ['AP', 'Ai', 'Aj', 'BA', 'BE', 'Bb', 'Bd', 'Bn', 'CL', 'CM', 'CU',\n",
    "       'CZ', 'Cl', 'DH', 'DN', 'Dc', 'Dx', 'Ed', 'Eg', 'Er', 'FI', 'Fd',\n",
    "       'Fo', 'GD', 'GJ', 'Gb', 'Gx', 'Hj', 'IK', 'Id', 'JX', 'Jc', 'Jf',\n",
    "       'Jt', 'KR', 'KZ', 'Kf', 'Kq', 'LE', 'MC', 'MO', 'MV', 'Mf', 'Ml',\n",
    "       'Mx', 'NV', 'Nf', 'Nk', 'OR', 'Ob', 'Os', 'PA', 'PQ', 'PZ', 'Ps',\n",
    "       'QM', 'Qb', 'Qh', 'Qo', 'RG', 'RL', 'RP', 'Rm', 'Ry', 'SB', 'Sc',\n",
    "       'TR', 'TZ', 'To', 'UO', 'Uk', 'Uu', 'Vf', 'Vx', 'WE', 'Wc', 'Wv',\n",
    "       'XI', 'Xh', 'Xi', 'YC', 'Yb', 'Ye', 'ZR', 'ZS', 'Zc', 'Zq', 'aF',\n",
    "       'aM', 'aO', 'aP', 'ac', 'av', 'bF', 'bJ', 'be', 'cA', 'cG', 'cW',\n",
    "       'ck', 'cp', 'dB', 'dE', 'dN', 'dO', 'dP', 'dQ', 'dZ', 'dh', 'eG',\n",
    "       'eQ', 'eb', 'eg', 'ek', 'ex', 'fO', 'fh', 'gJ', 'gM', 'hL', 'hT',\n",
    "       'hh', 'hp', 'iT', 'ih', 'jS', 'jV', 'je', 'jp', 'kC', 'kE', 'kK',\n",
    "       'kL', 'kU', 'kW', 'ke', 'kr', 'kw', 'lF', 'lL', 'll', 'lx', 'mb',\n",
    "       'mc', 'mm', 'nX', 'nh', 'oC', 'oG', 'oH', 'oK', 'od', 'on', 'pa',\n",
    "       'ps', 'qA', 'qJ', 'qK', 'qP', 'qX', 'qo', 'qv', 'qw', 'rZ', 'ri',\n",
    "       'rp', 'sD', 'sV', 'sY', 'sn', 'su', 'tM', 'tP', 'tv', 'uJ', 'uS',\n",
    "       'ud', 'us', 'ut', 'ux', 'uy', 'vK', 'vq', 'vy', 'wu', 'wy', 'xP',\n",
    "       'xy', 'yN', 'yY', 'yc', 'zU']\n",
    "ord_para_num(nome, df_treino, categorias)\n",
    "\n",
    "\n",
    "coluna_ord = ['ord_5_v2']\n",
    "Plotar_cat(df_treino, coluna_ord, vis_row=1, vis_col=1)\n",
    "\n",
    "#Considerando que a variável ord_5 é o resultado da junção de 2 outras\n",
    "#sendo um caractere de uma variável e o outro de outra.\n",
    "categorias = ['AP', 'Ai', 'Aj', 'BA', 'BE', 'Bb', 'Bd', 'Bn', 'CL', 'CM', 'CU',\n",
    "       'CZ', 'Cl', 'DH', 'DN', 'Dc', 'Dx', 'Ed', 'Eg', 'Er', 'FI', 'Fd',\n",
    "       'Fo', 'GD', 'GJ', 'Gb', 'Gx', 'Hj', 'IK', 'Id', 'JX', 'Jc', 'Jf',\n",
    "       'Jt', 'KR', 'KZ', 'Kf', 'Kq', 'LE', 'MC', 'MO', 'MV', 'Mf', 'Ml',\n",
    "       'Mx', 'NV', 'Nf', 'Nk', 'OR', 'Ob', 'Os', 'PA', 'PQ', 'PZ', 'Ps',\n",
    "       'QM', 'Qb', 'Qh', 'Qo', 'RG', 'RL', 'RP', 'Rm', 'Ry', 'SB', 'Sc',\n",
    "       'TR', 'TZ', 'To', 'UO', 'Uk', 'Uu', 'Vf', 'Vx', 'WE', 'Wc', 'Wv',\n",
    "       'XI', 'Xh', 'Xi', 'YC', 'Yb', 'Ye', 'ZR', 'ZS', 'Zc', 'Zq', 'aF',\n",
    "       'aM', 'aO', 'aP', 'ac', 'av', 'bF', 'bJ', 'be', 'cA', 'cG', 'cW',\n",
    "       'ck', 'cp', 'dB', 'dE', 'dN', 'dO', 'dP', 'dQ', 'dZ', 'dh', 'eG',\n",
    "       'eQ', 'eb', 'eg', 'ek', 'ex', 'fO', 'fh', 'gJ', 'gM', 'hL', 'hT',\n",
    "       'hh', 'hp', 'iT', 'ih', 'jS', 'jV', 'je', 'jp', 'kC', 'kE', 'kK',\n",
    "       'kL', 'kU', 'kW', 'ke', 'kr', 'kw', 'lF', 'lL', 'll', 'lx', 'mb',\n",
    "       'mc', 'mm', 'nX', 'nh', 'oC', 'oG', 'oH', 'oK', 'od', 'on', 'pa',\n",
    "       'ps', 'qA', 'qJ', 'qK', 'qP', 'qX', 'qo', 'qv', 'qw', 'rZ', 'ri',\n",
    "       'rp', 'sD', 'sV', 'sY', 'sn', 'su', 'tM', 'tP', 'tv', 'uJ', 'uS',\n",
    "       'ud', 'us', 'ut', 'ux', 'uy', 'vK', 'vq', 'vy', 'wu', 'wy', 'xP',\n",
    "       'xy', 'yN', 'yY', 'yc', 'zU']\n",
    "\n",
    "\n",
    "ord_5_v3 = []\n",
    "ord_5_v4 = []\n",
    "\n",
    "for f in df_treino.ord_5.iteritems():\n",
    "    lista = list(f)\n",
    "    ord_5_v3.append(f[0])\n",
    "    ord_5_v4.append(f[1])\n",
    "\n",
    "df_treino['ord_5_v3'] = ord_5_v3\n",
    "df_treino['ord_5_v4'] = ord_5_v4\n",
    "\n",
    "df_treino.columns\n",
    "\n",
    "coluna_ord = ['ord_5_v4']\n",
    "Plotar_cat(df_treino, coluna_ord, vis_row=1, vis_col=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Análise da Dados Cíclicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df_treino)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.countplot(x='day', hue='target', data=df_treino, palette=colores)\n",
    "g.set_title(\"Contagem das Classes\", fontsize = 20)\n",
    "g.set_xlabel(\"Dia\", fontsize = 15)\n",
    "g.set_ylabel(\"Contagem\", fontsize = 15)\n",
    "sizes=[]\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=14)\n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df_treino)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.countplot(x='month', hue='target', data=df_treino, palette=colores)\n",
    "g.set_title(\"Contagem das Classes\", fontsize = 20)\n",
    "g.set_xlabel(\"Mes\", fontsize = 15)\n",
    "g.set_ylabel(\"Contagem\", fontsize = 15)\n",
    "sizes=[]\n",
    "# código para porcentagens em cada barra\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 6,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=14)\n",
    "g.set_ylim(0, max(sizes) * 1.15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trabalharemos com os dois dataset juntos, até a etapa do aprendizado de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([treino, teste], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Precisamos converter alguns dados para que a análise tenha maior confiabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Verificando as classes nas variáveis ordinais e transformado-as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ord0 = df['ord_0'].unique()\n",
    "unique_ord1 = df['ord_1'].unique()\n",
    "unique_ord2 = df['ord_2'].unique()\n",
    "unique_ord3 = df['ord_3'].unique()\n",
    "unique_ord4 = df['ord_4'].unique()\n",
    "unique_ord5 = df['ord_5'].unique()\n",
    "\n",
    "\n",
    "#Transformações\n",
    "nome = 'ord_1'\n",
    "categorias = ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster']\n",
    "ord_para_fac(df, nome, categorias)\n",
    "\n",
    "nome = 'ord_2'\n",
    "categorias = ['Frezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']\n",
    "ord_para_fac(df, nome, categorias)\n",
    "\n",
    "nome = 'ord_3'\n",
    "categorias = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o']\n",
    "ord_para_num(nome, df, categorias)\n",
    "\n",
    "nome = 'ord_4'\n",
    "categorias = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "ord_para_num(nome, df, categorias)\n",
    "\n",
    "ord_5_v3 = []\n",
    "ord_5_v4 = []\n",
    "\n",
    "for i in df.ord_5.iteritems():\n",
    "    lista = list(i)\n",
    "    ord_5_v3.append(i[0])\n",
    "    ord_5_v4.append(i[1])\n",
    "\n",
    "df['ord_5_v3'] = ord_5_v3\n",
    "\n",
    "\n",
    "nome = 'ord_5_v3'\n",
    "categorias = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "ord_para_num(nome, df, categorias)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Verificando as classes nas variáveis binárias e transformado-as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Além de tratar das variáveis cíclicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_bin3 = df['bin_3'].unique()\n",
    "unique_bin4 = df['bin_4'].unique()\n",
    "\n",
    "nome = 'bin_3'\n",
    "categorias = ['T', 'F']\n",
    "ord_para_num(nome, df, categorias)\n",
    "\n",
    "nome = 'bin_4'\n",
    "categorias = ['Y', 'N']\n",
    "ord_para_num(nome, df, categorias)\n",
    "\n",
    "#Tratamento da Variáveis Cíclicas\n",
    "df['quarters'] = pd.to_datetime(df['month'].values, format='%m').astype('period[Q]')\n",
    "df_mes = pd.get_dummies(df['quarters'], prefix='v2', drop_first=False)\n",
    "df = pd.concat([df, df_mes], axis=1)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Copiar dados para evitar de perder tudo do dataset original e drop de algumas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df.drop(['bin_3', 'bin_4', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'month', 'quarters', 'ord_5_v3'], axis=1, inplace=True)   \n",
    "new_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Criação da Matriz Esparsa - One Hot Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [i for i in new_df.columns]\n",
    "print(columns)\n",
    "\n",
    "dummies = pd.get_dummies(new_df, columns=columns, drop_first=True, sparse=True)\n",
    "dummies.shape\n",
    "\n",
    "treino = dummies.iloc[:treino.shape[0], :]\n",
    "teste = dummies.iloc[treino.shape[0]:, :]\n",
    "treino = treino.fillna(0)\n",
    "treino.head(5)\n",
    "\n",
    "treino = treino.sparse.to_coo().tocsr()\n",
    "teste = teste.sparse.to_coo().tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preparação do Modelo e Avaliação da Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "cv_size = 0.30\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(treino, y, test_size=cv_size, random_state=seed)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict_proba(X_cv)[:, 1]\n",
    "roc_score = roc_auc_score(y_cv, prediction)\n",
    "print(roc_score)\n",
    "\n",
    "\n",
    "lr_cv = LogisticRegressionCV(Cs=7,\n",
    "                        solver=\"lbfgs\",\n",
    "                        tol=0.0002,\n",
    "                        max_iter=10000,\n",
    "                        cv=5,\n",
    "                        n_jobs=6)\n",
    "\n",
    "lr_cv.fit(treino, y)\n",
    "\n",
    "lr_cv_pred = lr_cv.predict_proba(treino)[:, 1]\n",
    "score = roc_auc_score(y, lr_cv_pred)\n",
    "\n",
    "print(\"Pontuacao: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Geração do Arquivo de Submissão ao Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissao[\"id\"] = teste_id\n",
    "submissao[\"target\"] = lr_cv.predict_proba(teste)[:, 1]\n",
    "display(submissao.head())\n",
    "\n",
    "submissao.set_index(\"id\",inplace=True)\n",
    "submissao.head()\n",
    "submissao.to_csv(\"submission_verX.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
